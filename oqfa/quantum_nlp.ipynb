{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae42340c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# %%\n",
    "# Quantum helpers\n",
    "\n",
    "def pure_density(vec):\n",
    "    v = np.array(vec, dtype=complex).reshape((-1,1))\n",
    "    return v @ v.conj().T\n",
    "\n",
    "def depolarizing_kraus(p):\n",
    "    I = np.array([[1,0],[0,1]], dtype=complex)\n",
    "    X = np.array([[0,1],[1,0]], dtype=complex)\n",
    "    Y = np.array([[0,-1j],[1j,0]], dtype=complex)\n",
    "    Z = np.array([[1,0],[0,-1]], dtype=complex)\n",
    "    k0 = np.sqrt(max(0.0, 1 - 3*p/4)) * I\n",
    "    k1 = np.sqrt(max(0.0, p/4)) * X\n",
    "    k2 = np.sqrt(max(0.0, p/4)) * Y\n",
    "    k3 = np.sqrt(max(0.0, p/4)) * Z\n",
    "    return [k0, k1, k2, k3]\n",
    "\n",
    "def apply_kraus(rho, kraus_list):\n",
    "    out = np.zeros_like(rho, dtype=complex)\n",
    "    for K in kraus_list:\n",
    "        out += K @ rho @ K.conj().T\n",
    "    out = (out + out.conj().T) / 2.0\n",
    "    tr = np.trace(out)\n",
    "    if np.abs(tr) > 1e-12:\n",
    "        out = out / tr\n",
    "    return out\n",
    "\n",
    "def purity_of(rho):\n",
    "    return float(np.real_if_close(np.trace(rho @ rho)))\n",
    "\n",
    "def von_neumann_entropy(rho):\n",
    "    vals = np.linalg.eigvalsh(rho)\n",
    "    vals = np.clip(vals, 1e-12, None)\n",
    "    return float(-np.sum(vals * np.log2(vals)))\n",
    "\n",
    "# %%\n",
    "# Models\n",
    "\n",
    "class PFA:\n",
    "    def __init__(self):\n",
    "        self.initial = np.array([1.0,0.0])\n",
    "        self.transitions = {}\n",
    "        self.accepting = {0}\n",
    "    def add_transition(self, symbol, matrix):\n",
    "        self.transitions[symbol] = np.array(matrix, dtype=float)\n",
    "    def recognize(self, s):\n",
    "        p = self.initial.copy()\n",
    "        for ch in s:\n",
    "            if ch in self.transitions:\n",
    "                p = self.transitions[ch] @ p\n",
    "            p = np.clip(p, 0, None)\n",
    "            ssum = p.sum()\n",
    "            if ssum > 0:\n",
    "                p = p / ssum\n",
    "        return float(np.sum([p[i] for i in self.accepting]))\n",
    "\n",
    "class OQFA:\n",
    "    def __init__(self):\n",
    "        self.rho0 = pure_density(np.array([1.0,0.0], dtype=complex))\n",
    "        self.transitions = {}\n",
    "        self.accepting = {0}\n",
    "    def add_transition(self, symbol, U, depolarizing_p=0.0):\n",
    "        self.transitions[symbol] = (np.array(U, dtype=complex), float(depolarizing_p))\n",
    "    def recognize(self, s, return_rho=False):\n",
    "        rho = self.rho0.copy()\n",
    "        for ch in s:\n",
    "            if ch in self.transitions:\n",
    "                U, p = self.transitions[ch]\n",
    "                rho = U @ rho @ U.conj().T\n",
    "                if p > 0:\n",
    "                    rho = apply_kraus(rho, depolarizing_kraus(p))\n",
    "        p_accept = float(np.real_if_close(rho[0,0].real))\n",
    "        if return_rho:\n",
    "            return p_accept, rho\n",
    "        return p_accept\n",
    "\n",
    "# %%\n",
    "# Dataset\n",
    "\n",
    "intents = {\n",
    "    'lights_on': [\"turn on the lights\", \"lights on\", \"switch lights on\", \"turn lights on\"],\n",
    "    'lights_off': [\"turn off the lights\", \"lights off\", \"switch lights off\", \"turn lights off\"],\n",
    "    'play_music': [\"play music\", \"play some music\", \"start music\", \"play songs\"],\n",
    "    'stop_music': [\"stop music\", \"pause music\", \"stop the music\", \"pause songs\"],\n",
    "    'call_contact': [\"call mom\", \"call dad\", \"call Alice\", \"make a call to Bob\"],\n",
    "    'get_weather': [\"what's the weather\", \"weather update\", \"what is the weather today\", \"tell me the weather\"]\n",
    "}\n",
    "\n",
    "import re\n",
    "\n",
    "def tokenize_command(cmd):\n",
    "    cmd = cmd.lower()\n",
    "    cmd = re.sub(r\"[^\\w\\s]\", \"\", cmd)\n",
    "    return cmd.split()\n",
    "\n",
    "all_rows = []\n",
    "for label, phrases in intents.items():\n",
    "    for ph in phrases:\n",
    "        toks = tokenize_command(ph)\n",
    "        all_rows.append((toks, label))\n",
    "        if len(toks) > 1:\n",
    "            all_rows.append((toks[:-1], label))\n",
    "        if len(toks) > 0:\n",
    "            t2 = toks.copy()\n",
    "            t2[0] = 'please'\n",
    "            all_rows.append((t2, label))\n",
    "        if len(toks) > 2:\n",
    "            t3 = toks.copy()\n",
    "            random.shuffle(t3)\n",
    "            all_rows.append((t3, label))\n",
    "\n",
    "from collections import Counter\n",
    "counter = Counter()\n",
    "for toks,_ in all_rows:\n",
    "    counter.update(toks)\n",
    "vocab = [tok for tok,_ in counter.most_common(20)]\n",
    "symbols = list('abcdefghijklmnopqrstuvwxyz')[:len(vocab)+1]\n",
    "token_to_symbol = {tok: symbols[i] for i,tok in enumerate(vocab)}\n",
    "token_to_symbol['<UNK>'] = symbols[len(vocab)]\n",
    "\n",
    "def tokens_to_string(toks):\n",
    "    return ''.join([token_to_symbol.get(t, token_to_symbol['<UNK>']) for t in toks])\n",
    "\n",
    "rows = [{'sequence': tokens_to_string(toks), 'label': label, 'tokens': ' '.join(toks)}\n",
    "        for toks,label in all_rows]\n",
    "\n",
    "df = pd.DataFrame(rows).sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "df.head(20)\n",
    "\n",
    "# %%\n",
    "# Splits\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, random_state=0, stratify=df['label'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=0, stratify=temp_df['label'])\n",
    "\n",
    "print('Train size:', len(train_df), 'Val size:', len(val_df), 'Test size:', len(test_df))\n",
    "\n",
    "# %%\n",
    "# Builders\n",
    "\n",
    "def build_baseline_pfa_for_vocab(df):\n",
    "    pfa = PFA()\n",
    "    alphabet = set(''.join(df['sequence'].tolist()))\n",
    "    for sym in alphabet:\n",
    "        pfa.add_transition(sym, [[0.6,0.4],[0.4,0.6]])\n",
    "    return pfa\n",
    "\n",
    "def build_param_oqfa_for_vocab(theta, depolarizing_p, df):\n",
    "    U = np.array([[math.cos(theta), -math.sin(theta)],\n",
    "                  [math.sin(theta),  math.cos(theta)]], dtype=complex)\n",
    "    oq = OQFA()\n",
    "    alphabet = set(''.join(df['sequence'].tolist()))\n",
    "    for sym in alphabet:\n",
    "        oq.add_transition(sym, U, depolarizing_p=depolarizing_p)\n",
    "    return oq\n",
    "\n",
    "# %%\n",
    "# One-vs-rest training\n",
    "\n",
    "target_intent = 'play_music'\n",
    "train_labels = (train_df['label']==target_intent).astype(int).to_numpy()\n",
    "val_labels = (val_df['label']==target_intent).astype(int).to_numpy()\n",
    "test_labels = (test_df['label']==target_intent).astype(int).to_numpy()\n",
    "\n",
    "train_seqs = train_df['sequence'].tolist()\n",
    "val_seqs = val_df['sequence'].tolist()\n",
    "test_seqs = test_df['sequence'].tolist()\n",
    "\n",
    "theta_candidates = np.linspace(-math.pi/2, math.pi/2, 9)\n",
    "noise_candidates = [0.0, 0.02, 0.05, 0.08]\n",
    "threshold_candidates = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "records = []\n",
    "best = None\n",
    "\n",
    "for p in noise_candidates:\n",
    "    for th in theta_candidates:\n",
    "        oq = build_param_oqfa_for_vocab(th, p, df)\n",
    "        acc_train = np.array([oq.recognize(s) for s in train_seqs])\n",
    "        acc_val = np.array([oq.recognize(s) for s in val_seqs])\n",
    "        for thr in threshold_candidates:\n",
    "            preds_val = (acc_val >= thr).astype(int)\n",
    "            f1 = f1_score(val_labels, preds_val, zero_division=0)\n",
    "            acc = accuracy_score(val_labels, preds_val)\n",
    "            try:\n",
    "                auc = roc_auc_score(val_labels, acc_val)\n",
    "            except Exception:\n",
    "                auc = None\n",
    "            records.append({'p':p, 'theta':th, 'threshold':thr,\n",
    "                            'val_acc':acc, 'val_f1':f1, 'val_auc':auc})\n",
    "            if best is None or f1 > best['score']:\n",
    "                best = {'score':f1, 'p':p, 'theta':th,\n",
    "                        'threshold':thr, 'model':deepcopy(oq)}\n",
    "\n",
    "results_df = pd.DataFrame(records).sort_values(['val_f1'], ascending=False)\n",
    "results_df.head(20)\n",
    "\n",
    "# %%\n",
    "# Evaluation\n",
    "\n",
    "best_model = best['model']\n",
    "best_params = {k:v for k,v in best.items() if k!='model'}\n",
    "\n",
    "test_accepts = np.array([best_model.recognize(s) for s in test_seqs])\n",
    "thr = best_params['threshold']\n",
    "preds_test = (test_accepts >= thr).astype(int)\n",
    "\n",
    "print('Best params:', best_params)\n",
    "print('Test accuracy:', accuracy_score(test_labels, preds_test))\n",
    "print('Test precision:', precision_score(test_labels, preds_test, zero_division=0))\n",
    "print('Test recall:', recall_score(test_labels, preds_test, zero_division=0))\n",
    "print('Test f1:', f1_score(test_labels, preds_test, zero_division=0))\n",
    "\n",
    "# %%\n",
    "# Plots\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(test_accepts[test_labels==0], bins=15, alpha=0.6, label='other')\n",
    "plt.hist(test_accepts[test_labels==1], bins=15, alpha=0.6, label=target_intent)\n",
    "plt.xlabel('OQFA acceptance')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.title(f'Acceptance distribution for {target_intent}')\n",
    "plt.show()\n",
    "\n",
    "acc_vs_noise = results_df.groupby('p')['val_f1'].mean().reset_index()\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(acc_vs_noise['p'], acc_vs_noise['val_f1'], marker='o')\n",
    "plt.xlabel('Depolarizing noise p')\n",
    "plt.ylabel('Mean validation F1')\n",
    "plt.title('Validation F1 vs noise')\n",
    "plt.show()\n",
    "\n",
    "pur_rows = []\n",
    "for p in noise_candidates:\n",
    "    oq_tmp = build_param_oqfa_for_vocab(best_params['theta'], p, df)\n",
    "    purities = []\n",
    "    for s in test_seqs:\n",
    "        _, rho = oq_tmp.recognize(s, return_rho=True)\n",
    "        purities.append(purity_of(rho))\n",
    "    pur_rows.append({'p':p, 'purity':float(np.mean(purities))})\n",
    "\n",
    "df_pur = pd.DataFrame(pur_rows)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(df_pur['p'], df_pur['purity'], marker='o')\n",
    "plt.xlabel('Depolarizing noise p')\n",
    "plt.ylabel('Mean purity')\n",
    "plt.title('Purity vs noise')\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Save results\n",
    "\n",
    "outdir = './oqfa_intent_outputs'\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "results_df.to_csv(os.path.join(outdir, 'oqfa_intent_grid_search.csv'), index=False)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'sequence':test_seqs,\n",
    "    'acceptance':test_accepts,\n",
    "    'label':test_df['label'].tolist(),\n",
    "    'pred':preds_test\n",
    "}).to_csv(os.path.join(outdir, 'oqfa_intent_test_preds.csv'), index=False)\n",
    "\n",
    "summary = {\n",
    "    'best_params':best_params,\n",
    "    'test_metrics':{\n",
    "        'accuracy':float(accuracy_score(test_labels, preds_test)),\n",
    "        'precision':float(precision_score(test_labels, preds_test, zero_division=0)),\n",
    "        'recall':float(recall_score(test_labels, preds_test, zero_division=0)),\n",
    "        'f1':float(f1_score(test_labels, preds_test, zero_division=0))\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(outdir, 'oqfa_intent_summary.json'), 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print('Saved outputs to', outdir)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
