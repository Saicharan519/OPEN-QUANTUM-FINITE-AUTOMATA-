{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8aa638",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os, json, math\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# -----------------------------------\n",
    "# Utilities: quantum/open-system helpers\n",
    "# -----------------------------------\n",
    "def pure_density(vec):\n",
    "    v = np.array(vec, dtype=complex).reshape((-1,1))\n",
    "    return v @ v.conj().T\n",
    "\n",
    "def depolarizing_kraus(p):\n",
    "    I = np.array([[1,0],[0,1]], dtype=complex)\n",
    "    X = np.array([[0,1],[1,0]], dtype=complex)\n",
    "    Y = np.array([[0,-1j],[1j,0]], dtype=complex)\n",
    "    Z = np.array([[1,0],[0,-1]], dtype=complex)\n",
    "    k0 = np.sqrt(max(0.0, 1 - 3*p/4)) * I\n",
    "    k1 = np.sqrt(max(0.0, p/4)) * X\n",
    "    k2 = np.sqrt(max(0.0, p/4)) * Y\n",
    "    k3 = np.sqrt(max(0.0, p/4)) * Z\n",
    "    return [k0, k1, k2, k3]\n",
    "\n",
    "def apply_kraus(rho, kraus_list):\n",
    "    out = np.zeros_like(rho, dtype=complex)\n",
    "    for K in kraus_list:\n",
    "        out += K @ rho @ K.conj().T\n",
    "    out = (out + out.conj().T) / 2.0\n",
    "    tr = np.trace(out)\n",
    "    if np.abs(tr) > 1e-12:\n",
    "        out = out / tr\n",
    "    return out\n",
    "\n",
    "def purity_of(rho):\n",
    "    return float(np.real_if_close(np.trace(rho @ rho)))\n",
    "\n",
    "def von_neumann_entropy(rho):\n",
    "    vals = np.linalg.eigvalsh(rho)\n",
    "    vals = np.clip(vals, 1e-12, None)\n",
    "    return float(-np.sum(vals * np.log2(vals)))\n",
    "\n",
    "# -----------------------------------\n",
    "# Models: PFA, OQFA (very small)\n",
    "# -----------------------------------\n",
    "class PFA:\n",
    "    def __init__(self):\n",
    "        self.initial = np.array([1.0, 0.0])\n",
    "        self.transitions = {}\n",
    "        self.accepting = {0}\n",
    "    def add_transition(self, symbol, matrix):\n",
    "        self.transitions[symbol] = np.array(matrix, dtype=float)\n",
    "    def recognize(self, s):\n",
    "        p = self.initial.copy()\n",
    "        for ch in s:\n",
    "            if ch in self.transitions:\n",
    "                p = self.transitions[ch] @ p\n",
    "            # else: ignore unknown symbol (no-op)\n",
    "            p = np.clip(p, 0, None)\n",
    "            ssum = p.sum()\n",
    "            if ssum > 0:\n",
    "                p = p / ssum\n",
    "        return float(np.sum([p[i] for i in self.accepting]))\n",
    "\n",
    "class OQFA:\n",
    "    def __init__(self):\n",
    "        self.rho0 = pure_density(np.array([1.0, 0.0], dtype=complex))\n",
    "        self.transitions = {}  # symbol -> (U, depolarizing_p)\n",
    "        self.accepting = {0}\n",
    "    def add_transition(self, symbol, U, depolarizing_p=0.0):\n",
    "        self.transitions[symbol] = (np.array(U, dtype=complex), float(depolarizing_p))\n",
    "    def recognize(self, s, return_rho=False):\n",
    "        rho = self.rho0.copy()\n",
    "        for ch in s:\n",
    "            if ch in self.transitions:\n",
    "                U, p = self.transitions[ch]\n",
    "                rho = U @ rho @ U.conj().T\n",
    "                if p > 0:\n",
    "                    rho = apply_kraus(rho, depolarizing_kraus(p))\n",
    "        p_accept = float(np.real_if_close(rho[0,0].real))\n",
    "        if return_rho:\n",
    "            return p_accept, rho\n",
    "        return p_accept\n",
    "\n",
    "# -----------------------------------\n",
    "# Synthetic dataset generation\n",
    "# -----------------------------------\n",
    "SYMBOLS = ['L','A','T','O','V','F']  # L=login, A=add beneficiary, T=transfer, O=logout, V=view, F=failed_auth\n",
    "\n",
    "NORMAL_TEMPLATES = [\n",
    "    ['L','V','O'],\n",
    "    ['L','T','O'],\n",
    "    ['L','A','T','O'],\n",
    "    ['L','V','V','O']\n",
    "]\n",
    "\n",
    "FRAUD_TEMPLATES = [\n",
    "    ['L','A','T','O'],\n",
    "    ['L','F','F','T','O'],\n",
    "    ['L','A','A','T','O'],\n",
    "    ['L','T','T','O']\n",
    "]\n",
    "\n",
    "def generate_sequence_from_template(tmpl, insert_noise_prob=0.08, drop_prob=0.05, substitute_prob=0.03):\n",
    "    seq = []\n",
    "    for sym in tmpl:\n",
    "        if np.random.rand() < drop_prob:\n",
    "            continue\n",
    "        if np.random.rand() < substitute_prob:\n",
    "            choices = [s for s in SYMBOLS if s != sym]\n",
    "            seq.append(np.random.choice(choices))\n",
    "        else:\n",
    "            seq.append(sym)\n",
    "        if np.random.rand() < insert_noise_prob:\n",
    "            seq.append(np.random.choice(SYMBOLS))\n",
    "    return ''.join(seq)\n",
    "\n",
    "def create_synthetic_dataset(n_normal=400, n_fraud=200, noise_params=None, random_state=0):\n",
    "    if noise_params is None:\n",
    "        noise_params = {'insert_noise_prob':0.08, 'drop_prob':0.05, 'substitute_prob':0.03}\n",
    "    rows = []\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    for _ in range(n_normal):\n",
    "        tmpl = NORMAL_TEMPLATES[rng.randint(len(NORMAL_TEMPLATES))]\n",
    "        seq = generate_sequence_from_template(tmpl, **noise_params)\n",
    "        rows.append({'sequence': seq, 'label': 0})\n",
    "    for _ in range(n_fraud):\n",
    "        tmpl = FRAUD_TEMPLATES[rng.randint(len(FRAUD_TEMPLATES))]\n",
    "        seq = generate_sequence_from_template(tmpl, **noise_params)\n",
    "        rows.append({'sequence': seq, 'label': 1})\n",
    "    df = pd.DataFrame(rows).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# -----------------------------------\n",
    "# Model builders\n",
    "# -----------------------------------\n",
    "def build_baseline_pfa():\n",
    "    pfa = PFA()\n",
    "    pfa.add_transition('L', [[0.9,0.1],[0.1,0.9]])\n",
    "    pfa.add_transition('A', [[0.8,0.2],[0.2,0.8]])\n",
    "    pfa.add_transition('T', [[0.2,0.8],[0.8,0.2]])\n",
    "    pfa.add_transition('O', [[0.9,0.1],[0.1,0.9]])\n",
    "    pfa.add_transition('V', [[0.85,0.15],[0.15,0.85]])\n",
    "    pfa.add_transition('F', [[0.3,0.7],[0.7,0.3]])\n",
    "    return pfa\n",
    "\n",
    "def build_param_oqfa(theta_a, theta_b, depolarizing_p):\n",
    "    Ua = np.array([[math.cos(theta_a), -math.sin(theta_a)],\n",
    "                   [math.sin(theta_a),  math.cos(theta_a)]], dtype=complex)\n",
    "    Ub = np.array([[math.cos(theta_b), -math.sin(theta_b)],\n",
    "                   [math.sin(theta_b),  math.cos(theta_b)]], dtype=complex)\n",
    "    oq = OQFA()\n",
    "    oq.add_transition('A', Ua, depolarizing_p=depolarizing_p)\n",
    "    oq.add_transition('T', Ub, depolarizing_p=depolarizing_p)\n",
    "    I = np.eye(2, dtype=complex)\n",
    "    for s in ['L','O','V','F']:\n",
    "        oq.add_transition(s, I, depolarizing_p=depolarizing_p)\n",
    "    return oq\n",
    "\n",
    "# -----------------------------------\n",
    "# Evaluation & grid search\n",
    "# -----------------------------------\n",
    "def acceptances_for_model(model, sequences):\n",
    "    return np.array([model.recognize(s) for s in sequences])\n",
    "\n",
    "def evaluate_thresholded(acceptances, labels, thr):\n",
    "    preds = (acceptances >= thr).astype(int)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, zero_division=0)\n",
    "    rec = recall_score(labels, preds, zero_division=0)\n",
    "    f1 = f1_score(labels, preds, zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, acceptances)\n",
    "    except Exception:\n",
    "        auc = None\n",
    "    return {'acc':acc, 'prec':prec, 'rec':rec, 'f1':f1, 'auc':auc, 'preds':preds}\n",
    "\n",
    "# -----------------------------------\n",
    "# Main flow\n",
    "# -----------------------------------\n",
    "def main():\n",
    "    outdir = \"./oqfa_fraud_outputs\"\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # create dataset\n",
    "    df = create_synthetic_dataset(n_normal=800, n_fraud=400,\n",
    "                                  noise_params={'insert_noise_prob':0.12, 'drop_prob':0.08, 'substitute_prob':0.06},\n",
    "                                  random_state=0)\n",
    "    df.to_csv(os.path.join(outdir, \"synthetic_transactions.csv\"), index=False)\n",
    "\n",
    "    # splits\n",
    "    train_df, temp = train_test_split(df, test_size=0.4, random_state=0, stratify=df['label'])\n",
    "    val_df, test_df = train_test_split(temp, test_size=0.5, random_state=0, stratify=temp['label'])\n",
    "    train_df.to_csv(os.path.join(outdir, \"train.csv\"), index=False)\n",
    "    val_df.to_csv(os.path.join(outdir, \"val.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(outdir, \"test.csv\"), index=False)\n",
    "\n",
    "    # coarse grid search\n",
    "    theta_candidates = np.linspace(-math.pi/3, math.pi/3, 7)\n",
    "    noise_candidates = [0.0, 0.02, 0.05, 0.08]\n",
    "    threshold_candidates = [0.35, 0.45, 0.5, 0.55, 0.65]\n",
    "\n",
    "    train_seqs = train_df['sequence'].tolist()\n",
    "    train_labels = train_df['label'].to_numpy()\n",
    "    val_seqs = val_df['sequence'].tolist()\n",
    "    val_labels = val_df['label'].to_numpy()\n",
    "\n",
    "    results = []\n",
    "    best = None\n",
    "\n",
    "    for p in noise_candidates:\n",
    "        for ta in theta_candidates:\n",
    "            for tb in theta_candidates:\n",
    "                oq = build_param_oqfa(ta, tb, p)\n",
    "                acc_train = acceptances_for_model(oq, train_seqs)\n",
    "                acc_val = acceptances_for_model(oq, val_seqs)\n",
    "                for thr in threshold_candidates:\n",
    "                    tr_stats = evaluate_thresholded(acc_train, train_labels, thr)\n",
    "                    val_stats = evaluate_thresholded(acc_val, val_labels, thr)\n",
    "                    results.append({\n",
    "                        'p': p, 'theta_a': ta, 'theta_b': tb, 'threshold': thr,\n",
    "                        'train_acc': tr_stats['acc'], 'val_acc': val_stats['acc'],\n",
    "                        'train_f1': tr_stats['f1'], 'val_f1': val_stats['f1'], 'val_auc': val_stats['auc'] if val_stats['auc'] is not None else float('nan')\n",
    "                    })\n",
    "                    if best is None or val_stats['acc'] > best['score']:\n",
    "                        best = {'score': val_stats['acc'], 'p': p, 'theta_a': ta, 'theta_b': tb, 'threshold': thr, 'model': deepcopy(oq)}\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values(['val_acc'], ascending=False)\n",
    "    results_df.to_csv(os.path.join(outdir, \"grid_search_results.csv\"), index=False)\n",
    "\n",
    "    # Evaluate best on test\n",
    "    best_model = best['model']\n",
    "    best_params = {k:v for k,v in best.items() if k!='model'}\n",
    "    test_seqs = test_df['sequence'].tolist()\n",
    "    test_labels = test_df['label'].to_numpy()\n",
    "    test_accepts = acceptances_for_model(best_model, test_seqs)\n",
    "    test_eval = evaluate_thresholded(test_accepts, test_labels, best_params['threshold'])\n",
    "\n",
    "    test_out = test_df.copy()\n",
    "    test_out['acceptance'] = test_accepts\n",
    "    test_out['pred'] = test_eval['preds']\n",
    "    test_out.to_csv(os.path.join(outdir, \"test_predictions.csv\"), index=False)\n",
    "\n",
    "    # Plots (matplotlib only; each plot separate)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(test_out[test_out['label']==0]['acceptance'], bins=20, alpha=0.7, label='normal')\n",
    "    plt.hist(test_out[test_out['label']==1]['acceptance'], bins=20, alpha=0.7, label='fraud')\n",
    "    plt.xlabel(\"OQFA acceptance\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"Acceptance distribution (test set)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, \"acceptance_distribution.png\"), dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    acc_vs_noise = results_df.groupby('p')['val_acc'].mean().reset_index()\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(acc_vs_noise['p'], acc_vs_noise['val_acc'], marker='o')\n",
    "    plt.xlabel(\"Depolarizing noise p\")\n",
    "    plt.ylabel(\"Mean validation accuracy\")\n",
    "    plt.title(\"Validation accuracy vs depolarizing noise\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, \"accuracy_vs_noise.png\"), dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    pur_rows = []\n",
    "    for p in noise_candidates:\n",
    "        oq_tmp = build_param_oqfa(best_params['theta_a'], best_params['theta_b'], p)\n",
    "        purities = []\n",
    "        entropies = []\n",
    "        for s in test_seqs:\n",
    "            pa, rho = oq_tmp.recognize(s, return_rho=True)\n",
    "            purities.append(purity_of(rho))\n",
    "            entropies.append(von_neumann_entropy(rho))\n",
    "        pur_rows.append({'p': p, 'purity': float(np.mean(purities)), 'entropy': float(np.mean(entropies))})\n",
    "    df_pur = pd.DataFrame(pur_rows)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(df_pur['p'], df_pur['purity'], marker='o')\n",
    "    plt.xlabel(\"Depolarizing noise p\")\n",
    "    plt.ylabel(\"Mean purity\")\n",
    "    plt.title(\"OQFA purity vs depolarizing noise (test set)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, \"purity_vs_noise.png\"), dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    summary = {\n",
    "        'best_val_accuracy': float(best['score']),\n",
    "        'best_params': {'p': float(best['p']), 'theta_a': float(best['theta_a']), 'theta_b': float(best['theta_b']), 'threshold': float(best['threshold'])},\n",
    "        'test_metrics': {'accuracy': float(test_eval['acc']), 'precision': float(test_eval['prec']), 'recall': float(test_eval['rec']), 'f1': float(test_eval['f1']), 'auc': float(test_eval['auc']) if test_eval['auc'] is not None else None}\n",
    "    }\n",
    "    with open(os.path.join(outdir, \"summary.json\"), \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(\"Done. Outputs written to:\", outdir)\n",
    "    print(\"Best validation accuracy:\", best['score'])\n",
    "    print(\"Best params:\", best_params)\n",
    "    print(\"Test metrics:\", summary['test_metrics'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
